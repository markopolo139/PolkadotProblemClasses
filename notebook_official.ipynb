{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import string\n",
    "import random\n",
    "import pygad\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_target(kpis):\n",
    "    return sum(5*(x_ref - x_ours) if x_ref > x_ours else x_ref - x_ours for x_ref, x_ours in kpis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KPIS_WEIGHTS = [1, -1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximized (1)\n",
    "def get_amount(solution):\n",
    "    solution2 = solution.loc[~(solution.drop(columns=\"amount\") == 0).all(axis=1)]\n",
    "    return solution2[\"amount\"].mean()\n",
    "\n",
    "\n",
    "def divide_amount_between_validators(solution):\n",
    "    amounts = solution[\"amount\"]\n",
    "    solution_amountless = solution.drop(columns=\"amount\")\n",
    "\n",
    "    mask = solution_amountless == 1\n",
    "    nominators_selected_validators_counts = mask.sum(axis=1)\n",
    "    safe_selected_counts = nominators_selected_validators_counts.replace(0, 1)\n",
    "\n",
    "    distributed_amounts = (amounts / safe_selected_counts).values[:, None] * mask\n",
    "\n",
    "    validators_to_money = distributed_amounts.sum(axis=0)\n",
    "\n",
    "    validators_to_money_dict = dict(zip(solution_amountless.columns, validators_to_money))\n",
    "\n",
    "    return validators_to_money_dict\n",
    "\n",
    "\n",
    "# Minimized (-1)\n",
    "def get_standard_deviation(solution):\n",
    "    return np.array(list(divide_amount_between_validators(solution).values())).std()\n",
    "\n",
    "\n",
    "# Minimized (-1)\n",
    "def get_assignment(solution):\n",
    "    nominatorsAssignments = (solution.iloc[:, :-1] == 1).sum(axis=1)\n",
    "    return ((nominatorsAssignments - 1) ** 2).sum()\n",
    "\n",
    "\n",
    "def create_kpis(solution):\n",
    "    solution_amount = get_amount(solution) * KPIS_WEIGHTS[0]\n",
    "    solution_variance = get_standard_deviation(solution) * KPIS_WEIGHTS[1]\n",
    "    solution_assignment = get_assignment(solution) * KPIS_WEIGHTS[2]\n",
    "\n",
    "    return [solution_amount, solution_variance, solution_assignment]\n",
    "\n",
    "\n",
    "def concatenate_solutions(sol1, sol2):\n",
    "    result = []\n",
    "    for s1, s2 in zip(sol1, sol2):\n",
    "        result.append((s1, s2))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def compare_solutions(sol1, sol2):\n",
    "    return calc_target(concatenate_solutions(create_kpis(sol1), create_kpis(sol2)))\n",
    "\n",
    "\n",
    "def get_data_batches(nominators_filepath_pattern='data/polkadot_nominators_session_*.csv', batch_size=1, default_min=0):\n",
    "    file_paths = glob.glob(nominators_filepath_pattern)\n",
    "    num_batches = len(file_paths) // batch_size + (1 if len(file_paths) % batch_size != 0 else 0)\n",
    "    data_batches = []\n",
    "    for i in range(num_batches):\n",
    "        nominators_batches = [pd.read_csv(file) for file in file_paths[i * batch_size: (i + 1) * batch_size]]\n",
    "        all_data = pd.concat(nominators_batches, ignore_index=True)\n",
    "        min_batch_amount = default_min if default_min == 0 else all_data[\"bonded_amount\"].min()\n",
    "        max_batch_amount = all_data[\"bonded_amount\"].max()\n",
    "\n",
    "        nominators_batches = list(map(lambda x: remove_empty_targets_row(x, min_batch_amount, max_batch_amount), nominators_batches))\n",
    "        data_batches.append(nominators_batches)\n",
    "    return data_batches\n",
    "\n",
    "\n",
    "def remove_empty_targets_row(nominators_df, min_amount, max_amount):\n",
    "    nominators_no_na = nominators_df[nominators_df[\"targets\"].notna()]\n",
    "    return normalize_amount_column(nominators_no_na, min_amount, max_amount)\n",
    "\n",
    "\n",
    "def normalize_amount_column(nominators_df, min_amount, max_amount):\n",
    "    nominators_df['bonded_amount'] = (nominators_df['bonded_amount'] - min_amount) / (max_amount - min_amount)\n",
    "    return nominators_df\n",
    "\n",
    "\n",
    "def flatten_solution(solution):\n",
    "    indices = solution.index.to_numpy()\n",
    "    data_matrix = solution.to_numpy()\n",
    "    return np.concatenate(np.hstack([\n",
    "        indices[:, None],\n",
    "        data_matrix\n",
    "    ]))\n",
    "\n",
    "\n",
    "def create_binary_matrix(nominators):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binary_matrix = mlb.fit_transform(nominators[\"targets\"].str.split(','))\n",
    "    binary_matrix = pd.DataFrame(binary_matrix, columns=mlb.classes_, index=nominators[\"stash_address\"])\n",
    "    binary_matrix[\"amount\"] = nominators.set_index(\"stash_address\")[\"bonded_amount\"]\n",
    "    return binary_matrix\n",
    "\n",
    "\n",
    "def create_random_solution(nominators, number_of_validators):\n",
    "    binary_matrix = create_binary_matrix(nominators)\n",
    "    binary_matrix_dropped = binary_matrix.drop(columns=\"amount\")\n",
    "    random_solution = binary_matrix_dropped.sample(n=number_of_validators, axis=1)\n",
    "    random_solution['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
    "    return random_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_cloud_url = \"https://storage.googleapis.com/watcher-csv-exporter/\"\n",
    "session_filename_template = string.Template(\"polkadot_nominators_session_$id.csv\")\n",
    "era_filename_template = string.Template(\"polkadot_validators_era_$id.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of data starting from era number 165 and session 1031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, destination):\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    with open(destination, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "\n",
    "def download_batch(starting_era=1000, starting_session=6041, destinationFolder=\"data/\", number_of_eras_to_download=1):\n",
    "    if os.path.exists(destinationFolder):\n",
    "         shutil.rmtree(destinationFolder)\n",
    "         \n",
    "    os.makedirs(destinationFolder, exist_ok=True)\n",
    "    era_id = starting_era\n",
    "    session_id = starting_session\n",
    "    total_eras_downloaded = 0\n",
    "\n",
    "    while total_eras_downloaded < number_of_eras_to_download:\n",
    "        era_filename = era_filename_template.substitute({'id': era_id})\n",
    "\n",
    "        try:\n",
    "            download_file(\n",
    "                google_cloud_url + era_filename,\n",
    "                destinationFolder + era_filename\n",
    "            )\n",
    "        except Exception as e:\n",
    "            era_id += 1\n",
    "            session_id += 6\n",
    "            continue\n",
    "        \n",
    "        session_filename = session_filename_template.substitute({'id': session_id})\n",
    "        download_file(\n",
    "            google_cloud_url + session_filename,\n",
    "            destinationFolder + session_filename\n",
    "        )\n",
    "\n",
    "        total_eras_downloaded += 1\n",
    "        era_id += 1\n",
    "        session_id += 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download of data and set basic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTING_ERA = 165\n",
    "STARTING_SESSION = 1031\n",
    "download_batch(starting_era=STARTING_ERA, starting_session=STARTING_SESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maksymilian\\AppData\\Local\\Temp\\ipykernel_11776\\1395643686.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ref_sol['amount'] = nominators.set_index('stash_address')['bonded_amount']\n"
     ]
    }
   ],
   "source": [
    "nominators = get_data_batches()[0][0]\n",
    "validators = pd.read_csv(f\"data/polkadot_validators_era_{STARTING_ERA}.csv\")\n",
    "number_of_validators = len(validators)\n",
    "binary_matrix = create_binary_matrix(nominators)\n",
    "val_pool = binary_matrix.columns\n",
    "val_pool = val_pool[:-1]\n",
    "val_pool = val_pool.to_list()\n",
    "ref_sol = binary_matrix[validators[\"stash_address\"]]\n",
    "ref_sol['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
    "ref_sol_kpis = create_kpis(ref_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gready Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Focus On total amount\n",
    "def solve_total_amount(nominators, num_of_vals):\n",
    "    binary_matrix = create_binary_matrix(nominators)\n",
    "    selected_validators = set()\n",
    "\n",
    "    binary_matrix.sort_values(by='amount', inplace=True, ascending=False)\n",
    "    i = 0\n",
    "\n",
    "    while len(selected_validators) < num_of_vals:\n",
    "        cols = binary_matrix.columns[binary_matrix.iloc[i] == 1].tolist()\n",
    "        to_add = num_of_vals - len(selected_validators)\n",
    "        if len(cols) <= to_add:\n",
    "            selected_validators.update(cols)\n",
    "        else:\n",
    "            selected_validators.update(cols[:to_add])\n",
    "        i += 1\n",
    "\n",
    "    result = binary_matrix[list(selected_validators)]\n",
    "    result['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Focus On total amount 2\n",
    "def solve_total_amount_2(nominators, num_of_vals):\n",
    "    nominators_copy = nominators.copy(deep=True)\n",
    "\n",
    "    nominators_copy['targets'] = nominators_copy['targets'].apply(lambda x: x.split(','))\n",
    "    \n",
    "    expanded_nominators = nominators_copy.explode('targets')\n",
    "    \n",
    "    validator_stakes = expanded_nominators.groupby('targets')['bonded_amount'].sum().reset_index()\n",
    "    validator_stakes = validator_stakes.rename(columns={'targets': 'validator_id', 'bonded_amount': 'total_stake'})\n",
    "    validator_stakes_sorted = validator_stakes.sort_values(by='total_stake', ascending=False)\n",
    "    selected_validators_df = validator_stakes_sorted.head(num_of_vals)\n",
    "    \n",
    "    binary_matrix = binary_matrix = create_binary_matrix(nominators)\n",
    "\n",
    "    return binary_matrix[list(selected_validators_df['validator_id']) + ['amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Focus on amount variance\n",
    "def solve_variance_only(nominators, num_of_vals):\n",
    "    nominators_copy = nominators.copy(deep=True)\n",
    "    nominators_copy['targets'] = nominators_copy['targets'].apply(lambda x: x.split(','))\n",
    "    expanded_nominators = nominators_copy.explode('targets')\n",
    "\n",
    "    validator_stakes = expanded_nominators.groupby('targets')['bonded_amount'].sum().reset_index()\n",
    "    validator_stakes = validator_stakes.rename(columns={'targets': 'validator_id', 'bonded_amount': 'total_stake'})\n",
    "    validator_stakes_sorted = validator_stakes.sort_values(by='total_stake', ascending=False)\n",
    "\n",
    "    selected_validators = []\n",
    "\n",
    "    for _, validator in validator_stakes_sorted.iterrows():\n",
    "        stakes = [v['total_stake'] for v in selected_validators] + [validator['total_stake']]\n",
    "        variance = np.var(stakes)\n",
    "\n",
    "        if len(selected_validators) < num_of_vals or variance < np.var(stakes[:-1]):\n",
    "            selected_validators.append(validator)\n",
    "\n",
    "        if len(selected_validators) >= num_of_vals:\n",
    "            break\n",
    "\n",
    "    selected_validators_df = pd.DataFrame(selected_validators)\n",
    "\n",
    "    binary_matrix = binary_matrix = create_binary_matrix(nominators)\n",
    "\n",
    "    return binary_matrix[list(selected_validators_df['validator_id']) + ['amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Focus on assignments\n",
    "def solve_assignments_only(nominators, num_of_vals):\n",
    "    nominators_copy = nominators.copy(deep=True)\n",
    "    nominators_copy['targets'] = nominators_copy['targets'].str.split(',')\n",
    "    nominators_copy_sorted = nominators_copy.sort_values(by=['num_targets', 'bonded_amount'], ascending=[False, False])\n",
    "\n",
    "    selected_validators = set()\n",
    "    encountered_validators = set()\n",
    "\n",
    "    for _, nominator in nominators_copy_sorted.iterrows():\n",
    "\n",
    "        if np.any([target in encountered_validators for target in nominator['targets']]):\n",
    "            continue\n",
    "        \n",
    "        if nominator['targets']:\n",
    "            chosen_validator = nominator['targets'][0]\n",
    "            selected_validators.add(chosen_validator)\n",
    "            encountered_validators.update(nominator['targets'])\n",
    "\n",
    "        if len(selected_validators) >= num_of_vals:\n",
    "            break\n",
    "\n",
    "    \n",
    "    if len(selected_validators) < num_of_vals:\n",
    "        nominators_copy_sorted = nominators_copy.sort_values(by=['num_targets', 'bonded_amount'], ascending=[True, False])\n",
    "        for _, nominator in nominators_copy_sorted.iterrows():\n",
    "            available_targets = [validator for validator in nominator['targets'] if validator not in selected_validators]\n",
    "            \n",
    "            if available_targets:\n",
    "                chosen_validator = available_targets[0]\n",
    "                selected_validators.add(chosen_validator)\n",
    "\n",
    "            if len(selected_validators) >= num_of_vals:\n",
    "                break\n",
    "\n",
    "    binary_matrix = binary_matrix = create_binary_matrix(nominators)\n",
    "\n",
    "    return binary_matrix[list(selected_validators) + ['amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Greedy\n",
    "def solve(nominators, num_of_vals):\n",
    "    nominators_copy = nominators.copy(deep=True)\n",
    "\n",
    "    nominators_copy['targets'] = nominators_copy['targets'].apply(lambda x: x.split(','))\n",
    "    \n",
    "    expanded_nominators = nominators_copy.explode('targets')\n",
    "    expanded_nominators['bonded_amount'] = expanded_nominators['bonded_amount'].astype(float)\n",
    "    \n",
    "    validator_stakes = expanded_nominators.groupby('targets')['bonded_amount'].sum().reset_index()\n",
    "    validator_stakes = validator_stakes.rename(columns={'targets': 'validator_id', 'bonded_amount': 'total_stake'})\n",
    "    validator_stakes_sorted = validator_stakes.sort_values(by='total_stake', ascending=False)\n",
    "\n",
    "    selected_validators = []\n",
    "    selected_nominators = set()\n",
    "\n",
    "    for _, validator in validator_stakes_sorted.iterrows():\n",
    "        validator_id = validator['validator_id']\n",
    "        validator_nominators = set(expanded_nominators[expanded_nominators['targets'] == validator_id]['stash_address'])\n",
    "        overlap = len(validator_nominators & selected_nominators)\n",
    "        \n",
    "        stakes = [v['total_stake'] for v in selected_validators] + [validator['total_stake']]\n",
    "        variance = np.var(stakes)\n",
    "        variance_tolerance = 0.009\n",
    "\n",
    "        if len(selected_validators) < num_of_vals or (overlap < 2 and variance - variance_tolerance < np.var(stakes[:-1])):\n",
    "            selected_validators.append(validator)\n",
    "            selected_nominators.update(validator_nominators)\n",
    "        \n",
    "        if len(selected_validators) >= num_of_vals:\n",
    "            break\n",
    "\n",
    "    selected_validators_df = pd.DataFrame(selected_validators)\n",
    "    \n",
    "    binary_matrix = binary_matrix = create_binary_matrix(nominators)\n",
    "\n",
    "    return binary_matrix[list(selected_validators_df['validator_id']) + ['amount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_solution(sol, val_pool=val_pool):\n",
    "    sol = sol.columns[:-1].tolist()\n",
    "    binary_vector = [0] * len(val_pool)\n",
    "    for validator in sol:\n",
    "        if validator in val_pool:\n",
    "            index = val_pool.index(validator)\n",
    "            binary_vector[index] = 1\n",
    "    \n",
    "    return binary_vector\n",
    "\n",
    "\n",
    "def decode_solution(encoded_sol, val_pool=val_pool, binary_matrix=binary_matrix):\n",
    "    decoded_list = []\n",
    "    for i, value in enumerate(encoded_sol):\n",
    "        if value == 1:\n",
    "            decoded_list.append(val_pool[i])\n",
    "\n",
    "    matching_columns = [col for col in decoded_list if col in binary_matrix.columns]\n",
    "    return binary_matrix[matching_columns + [binary_matrix.columns[-1]]]\n",
    "\n",
    "\n",
    "def fitness_func(ga_instance, solution, solution_idx):\n",
    "    decoded_solution = decode_solution(solution)\n",
    "    sol_kpis = create_kpis(decoded_solution)\n",
    "    sol_kpis[1], sol_kpis[2]\n",
    "    \n",
    "    fitness = calc_target(concatenate_solutions(ref_sol_kpis, sol_kpis))\n",
    "\n",
    "    return fitness * -1\n",
    "\n",
    "\n",
    "def mutate(solutions, ga_instance):\n",
    "    n = 5\n",
    "    offspring = []\n",
    "    for solution in solutions:\n",
    "        binary_vector = solution.copy()\n",
    "        ones_indices = [i for i, bit in enumerate(binary_vector) if bit == 1]\n",
    "        zeros_indices = [i for i, bit in enumerate(binary_vector) if bit == 0]\n",
    "\n",
    "        for _ in range(n):\n",
    "            one_to_zero = random.choice(ones_indices)\n",
    "            zero_to_one = random.choice(zeros_indices)\n",
    "\n",
    "            binary_vector[one_to_zero], binary_vector[zero_to_one] = 0, 1\n",
    "\n",
    "            ones_indices.remove(one_to_zero)\n",
    "            zeros_indices.append(one_to_zero)\n",
    "            zeros_indices.remove(zero_to_one)\n",
    "            ones_indices.append(zero_to_one)\n",
    "\n",
    "        offspring.append(binary_vector)\n",
    "    \n",
    "    return np.array(offspring)\n",
    "\n",
    "\n",
    "def crossover(parents, offspring_size, ga_instance):\n",
    "    offspring = []\n",
    "    while len(offspring) != offspring_size[0]:\n",
    "        temp_len = len(parents[0])\n",
    "        ones_p1 = [i for i, bit in enumerate(parents[0]) if bit == 1]\n",
    "        ones_p2 = [i for i, bit in enumerate(parents[1]) if bit == 1]\n",
    "        temp = len(ones_p1)\n",
    "        crossover_point = random.randint(1, temp - 1)\n",
    "        offspring1 = [0 for _ in range(temp_len)]\n",
    "        offspring2 = [0 for _ in range(temp_len)]\n",
    "\n",
    "        for i in range(crossover_point):\n",
    "            offspring1[ones_p1[i]] = 1\n",
    "            offspring2[ones_p2[i]] = 1\n",
    "\n",
    "        for i in range(crossover_point, temp):\n",
    "            if offspring1[ones_p2[i]] == 1 or offspring2[ones_p1[i]] == 1:\n",
    "                offspring1[ones_p1[i]] = 1\n",
    "                offspring2[ones_p2[i]] = 1\n",
    "            else:\n",
    "                offspring1[ones_p2[i]] = 1\n",
    "                offspring2[ones_p1[i]] = 1\n",
    "\n",
    "        offspring.append(offspring1)\n",
    "    \n",
    "\n",
    "    return np.array(offspring)\n",
    "\n",
    "\n",
    "def get_greedy_solutions():\n",
    "    population = [\n",
    "        encode_solution(solve(nominators, number_of_validators)),\n",
    "        encode_solution(solve_assignments_only(nominators, number_of_validators)),\n",
    "        encode_solution(solve_total_amount(nominators, number_of_validators)),\n",
    "        encode_solution(solve_total_amount_2(nominators, number_of_validators)),\n",
    "        encode_solution(solve_variance_only(nominators, number_of_validators))\n",
    "    ]\n",
    "    return population\n",
    "\n",
    "\n",
    "def fitness_func(ga_instance, solution, solution_idx):\n",
    "    decoded_solution = decode_solution(solution)\n",
    "    sol_kpis = create_kpis(decoded_solution)\n",
    "    sol_kpis[1], sol_kpis[2]\n",
    "    fitness = calc_target(concatenate_solutions(ref_sol_kpis, sol_kpis))\n",
    "\n",
    "    return fitness * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_population_size = 10\n",
    "num_generations = 10\n",
    "num_parents_mating = 2\n",
    "keep_elitssm = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorith\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_genetic_solution(nominators,\n",
    "                     num_of_vals,\n",
    "                     initial_pop_size=initial_population_size, \n",
    "                     num_gens=num_generations, \n",
    "                     num_pars_mating=num_parents_mating, \n",
    "                     keep_eli=keep_elitssm, \n",
    "                     fitness=fitness_func, crossover=crossover, mutate=mutate):\n",
    "\n",
    "    initial_population = get_greedy_solutions()\n",
    "\n",
    "    for _ in range(initial_pop_size - len(initial_population)):\n",
    "        initial_population.append(encode_solution(create_random_solution(nominators, num_of_vals), val_pool))\n",
    "\n",
    "    ga_instance = pygad.GA(num_generations=num_gens,\n",
    "                        num_parents_mating=num_pars_mating,\n",
    "                        fitness_func=fitness,\n",
    "                        initial_population=initial_population,\n",
    "                        crossover_type=crossover,\n",
    "                        mutation_type=mutate,\n",
    "                        keep_elitism=keep_eli\n",
    "                        )\n",
    "\n",
    "    ga_instance.run()\n",
    "\n",
    "    ga_solution, ga_solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "\n",
    "    # ga_instance.plot_fitness()\n",
    "\n",
    "    return decode_solution(ga_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solutions(n):\n",
    "    column_names = [\n",
    "        \"random solution\", \"solve total amount v1\", \"solve total amount v2\", \"solve variance only\", \"solve assignment only\", \"solve custom greedy\", \"solve genetic\"\n",
    "    ]\n",
    "    solutions = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        random = compare_solutions(ref_sol, create_random_solution(nominators, number_of_validators))\n",
    "        ta = compare_solutions(ref_sol, solve_total_amount(nominators, number_of_validators))\n",
    "        ta2 = compare_solutions(ref_sol, solve_total_amount_2(nominators, number_of_validators))\n",
    "        var = compare_solutions(ref_sol, solve_variance_only(nominators, number_of_validators))\n",
    "        ass = compare_solutions(ref_sol, solve_assignments_only(nominators, number_of_validators))\n",
    "        custom = compare_solutions(ref_sol, solve(nominators, number_of_validators))\n",
    "        gen = compare_solutions(ref_sol, solve_genetic_solution(nominators, number_of_validators))\n",
    "\n",
    "        solutions.append([random, ta, ta2, var, ass, custom, gen])\n",
    "\n",
    "    solutions_df = pd.DataFrame(solutions, columns=column_names)\n",
    "\n",
    "    return solutions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solutions():\n",
    "    random = compare_solutions(ref_sol, create_random_solution(nominators, number_of_validators))\n",
    "    ta = compare_solutions(ref_sol, solve_total_amount(nominators, number_of_validators))\n",
    "    ta2 =compare_solutions(ref_sol, solve_total_amount_2(nominators, number_of_validators))\n",
    "    var = compare_solutions(ref_sol, solve_variance_only(nominators, number_of_validators))\n",
    "    ass = compare_solutions(ref_sol, solve_assignments_only(nominators, number_of_validators))\n",
    "    custom = compare_solutions(ref_sol, solve(nominators, number_of_validators))\n",
    "    gen = compare_solutions(ref_sol, solve_genetic_solution(nominators, number_of_validators))\n",
    "                                         \n",
    "    return [random, ta, ta2, var, ass, custom, gen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maksymilian\\AppData\\Local\\Temp\\ipykernel_11776\\3681034135.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
      "C:\\Users\\Maksymilian\\AppData\\Local\\Temp\\ipykernel_11776\\3681034135.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
      "C:\\Users\\Maksymilian\\AppData\\Roaming\\Python\\Python312\\site-packages\\pygad\\pygad.py:1139: UserWarning: The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\n",
      "  warnings.warn(\"The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\")\n",
      "C:\\Users\\Maksymilian\\AppData\\Local\\Temp\\ipykernel_11776\\3681034135.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
      "C:\\Users\\Maksymilian\\AppData\\Local\\Temp\\ipykernel_11776\\3681034135.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
      "C:\\Users\\Maksymilian\\AppData\\Roaming\\Python\\Python312\\site-packages\\pygad\\pygad.py:1139: UserWarning: The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\n",
      "  warnings.warn(\"The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\")\n",
      "C:\\Users\\Maksymilian\\AppData\\Local\\Temp\\ipykernel_11776\\3681034135.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
      "C:\\Users\\Maksymilian\\AppData\\Local\\Temp\\ipykernel_11776\\3681034135.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
      "C:\\Users\\Maksymilian\\AppData\\Roaming\\Python\\Python312\\site-packages\\pygad\\pygad.py:1139: UserWarning: The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\n",
      "  warnings.warn(\"The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\")\n",
      "C:\\Users\\Maksymilian\\AppData\\Local\\Temp\\ipykernel_11776\\3681034135.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
      "C:\\Users\\Maksymilian\\AppData\\Local\\Temp\\ipykernel_11776\\3681034135.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
      "C:\\Users\\Maksymilian\\AppData\\Roaming\\Python\\Python312\\site-packages\\pygad\\pygad.py:1139: UserWarning: The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\n",
      "  warnings.warn(\"The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\")\n",
      "C:\\Users\\Maksymilian\\AppData\\Local\\Temp\\ipykernel_11776\\3681034135.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
      "C:\\Users\\Maksymilian\\AppData\\Local\\Temp\\ipykernel_11776\\3681034135.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['amount'] = nominators.set_index('stash_address')['bonded_amount']\n",
      "C:\\Users\\Maksymilian\\AppData\\Roaming\\Python\\Python312\\site-packages\\pygad\\pygad.py:1139: UserWarning: The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\n",
      "  warnings.warn(\"The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\")\n"
     ]
    }
   ],
   "source": [
    "solutions = get_solutions(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random solution</th>\n",
       "      <th>solve total amount v1</th>\n",
       "      <th>solve total amount v2</th>\n",
       "      <th>solve variance only</th>\n",
       "      <th>solve assignment only</th>\n",
       "      <th>solve custom greedy</th>\n",
       "      <th>solve genetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-393770.731311</td>\n",
       "      <td>-136634.960049</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>460275.240815</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>-430816.796663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-372731.796992</td>\n",
       "      <td>-136634.960049</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>460275.240815</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>-444893.809602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-388528.787772</td>\n",
       "      <td>-136634.960049</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>460275.240815</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>-424188.779404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-350539.798114</td>\n",
       "      <td>-136634.960049</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>460275.240815</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>-455326.808347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-409322.754043</td>\n",
       "      <td>-136634.960049</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>460275.240815</td>\n",
       "      <td>-4995.975583</td>\n",
       "      <td>-438125.760867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   random solution  solve total amount v1  solve total amount v2  \\\n",
       "0   -393770.731311         -136634.960049           -4995.975583   \n",
       "1   -372731.796992         -136634.960049           -4995.975583   \n",
       "2   -388528.787772         -136634.960049           -4995.975583   \n",
       "3   -350539.798114         -136634.960049           -4995.975583   \n",
       "4   -409322.754043         -136634.960049           -4995.975583   \n",
       "\n",
       "   solve variance only  solve assignment only  solve custom greedy  \\\n",
       "0         -4995.975583          460275.240815         -4995.975583   \n",
       "1         -4995.975583          460275.240815         -4995.975583   \n",
       "2         -4995.975583          460275.240815         -4995.975583   \n",
       "3         -4995.975583          460275.240815         -4995.975583   \n",
       "4         -4995.975583          460275.240815         -4995.975583   \n",
       "\n",
       "   solve genetic  \n",
       "0 -430816.796663  \n",
       "1 -444893.809602  \n",
       "2 -424188.779404  \n",
       "3 -455326.808347  \n",
       "4 -438125.760867  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPIC SOLVER 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epic_solver_3000(nominators, num_of_vals):\n",
    "    # step 1\n",
    "    binary_matrix = create_binary_matrix(nominators)\n",
    "    binary_matrix.sort_values(by='amount', inplace=True, ascending=False)\n",
    "    \n",
    "    # step 2\n",
    "    num_of_nominated_validators = binary_matrix.iloc[:, :-1].sum(axis=1)\n",
    "    binary_matrix_divided = binary_matrix.iloc[:, :-1].div(num_of_nominated_validators, axis=0)\n",
    "    amount_fraction_matrix = binary_matrix_divided.mul(binary_matrix['amount'], axis=0)\n",
    "\n",
    "    # step 3\n",
    "    column_sums = amount_fraction_matrix.sum(axis=0)\n",
    "    choosen_validators = column_sums.nlargest(num_of_vals).index\n",
    "\n",
    "    #step 4 \n",
    "    sol = binary_matrix[choosen_validators]\n",
    "    \n",
    "    sol_filtered = sol[(sol != 0).any(axis=1)]\n",
    "\n",
    "    sol_filtered_copy = sol_filtered.copy()\n",
    "\n",
    "    sol_filtered_copy['amount'] = binary_matrix.loc[sol_filtered.index, 'amount']\n",
    "\n",
    "    percentile_95 = sol_filtered_copy['amount'].quantile(0.99)\n",
    "    poors = sol_filtered_copy[sol_filtered_copy['amount'] <= percentile_95]\n",
    "    rich = sol_filtered_copy[sol_filtered_copy['amount'] > percentile_95]\n",
    "\n",
    "    poors_row_sums = poors.iloc[:, :-1].sum(axis=1)\n",
    "\n",
    "    poors_sorted = poors.assign(poors_row_sums=poors_row_sums).sort_values(\n",
    "        by=['poors_row_sums', 'amount'], \n",
    "        ascending=[True, False]\n",
    "    ).drop(columns='poors_row_sums') \n",
    "\n",
    "    rich_row_sums = rich.iloc[:, :-1].sum(axis=1)\n",
    "\n",
    "    rich_sorted = rich.assign(rich_row_sums=rich_row_sums).sort_values(\n",
    "        by=['rich_row_sums', 'amount'], \n",
    "        ascending=[True, False]\n",
    "    ).drop(columns='rich_row_sums') \n",
    "\n",
    "    solution = sol.copy()\n",
    "    solution = solution.astype(float)\n",
    "    validators_amount = pd.DataFrame([0.0] * len(sol.columns), index=sol.columns, columns=['amount']).T\n",
    "\n",
    "    for index, row in poors_sorted.iterrows():\n",
    "        selection = row.iloc[:-1]\n",
    "        amount = row.iloc[-1]\n",
    "        validators_selected = list(selection[selection == 1].index)\n",
    "\n",
    "        min_validator = validators_amount.loc['amount', validators_selected].idxmin()\n",
    "    \n",
    "        validators_amount.loc['amount', min_validator] += amount\n",
    "        solution.loc[index, min_validator] = amount\n",
    "\n",
    "\n",
    "    for index, row in rich_sorted.iterrows():\n",
    "        selection = row.iloc[:-1]\n",
    "        amount = row.iloc[-1]\n",
    "        validators_selected = list(selection[selection == 1].index)\n",
    "\n",
    "        validators_sum = validators_amount.loc['amount', validators_selected].sum()\n",
    "        total_sum = validators_sum + amount\n",
    "        sum_divided = total_sum / len(validators_selected)\n",
    "\n",
    "        remaining_amount = amount\n",
    "    \n",
    "        for validator in validators_selected:\n",
    "            current_amount = validators_amount.loc['amount', validator]\n",
    "            amount_to_add = sum_divided - current_amount\n",
    "            amount_to_add = min(amount_to_add, remaining_amount)\n",
    "            \n",
    "            validators_amount.loc['amount', validator] += amount_to_add\n",
    "\n",
    "            solution.loc[index, validator] = amount_to_add\n",
    "            \n",
    "            remaining_amount -= amount_to_add\n",
    "            \n",
    "            if remaining_amount <= 0:\n",
    "                break\n",
    "    \n",
    "    prev_std = 1.0\n",
    "    current_std = validators_amount.std(axis=1)['amount']\n",
    "    print(current_std)\n",
    "\n",
    "    while current_std < 0.9 * prev_std:\n",
    "        print('Iteration')\n",
    "        for index, row in poors_sorted.iterrows():\n",
    "            selection = row.iloc[:-1]\n",
    "            amount = row.iloc[-1]\n",
    "            validators_selected = list(selection[selection == 1].index)\n",
    "            \n",
    "            prev_selected_validator = solution[solution[index] != 0].index[0]\n",
    "\n",
    "            validators_amount[prev_selected_validator] -= amount\n",
    "\n",
    "            min_validator = validators_amount.loc['amount', validators_selected].idxmin()\n",
    "    \n",
    "            validators_amount.loc['amount', min_validator] += amount\n",
    "            solution.loc[index, min_validator] = amount\n",
    "\n",
    "        prev_std = current_std\n",
    "        current_std = validators_amount.std(axis=1)['amount']\n",
    "\n",
    "\n",
    "    return validators_amount.std(axis=1)['amount']\n",
    "\n",
    "\n",
    "zzz = epic_solver_3000(nominators, 297)\n",
    "zzz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
